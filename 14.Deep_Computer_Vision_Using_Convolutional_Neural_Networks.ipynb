{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Deep Computer Vision Using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) emerged from the study of the brain’s visual cortex, and they have been used in image recognition since the 1980s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers\n",
    "\n",
    "Neurons in the first convolutional layer are **not** connected to every pixel in the input image but only to pixels in their receptive fields. Successive layers only concentrate on a rectangle of neurons in the previous layers. \n",
    "\n",
    "**Note**: in CNNs each layer is in 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neuron located in row $i$, column $j$ of a given layer is connected to the outputs of the neurons in the previous layer located in rows $i$ to $i + f_h – 1$, columns $j$ to $j + f_w – 1$, where $f_h$ and $f_w$ are the height and width of the receptive field. In order to have same height and weight for layers, zeros are added around inputs (**Zero padding**).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN_Layers](images/13.CNN_Layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shift from one receptive field to the next is called the **stride**. The ouput layer can be smaller than the input layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters\n",
    "\n",
    "Or **convolutional kernels** can be represented as a small image the size of the receptive field. These weights will put particular emphasis to certain features of the data (hence the names _feature map_ for their otput), e.g. horizontal lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Multiple Feature Maps\n",
    "\n",
    "In short, a convolutional layer simultaneously applies multiple trainable filters to its inputs, making it capable of detecting multiple features anywhere in its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Implementation\n",
    "\n",
    "Input image = 3D tensor [_height, width, channels_]  \n",
    "Mini-batch = 4D tensor [_mini-batch size, height, width, channels_]  \n",
    "CNN weights = 4D tensor [$f_h$, $f_w$, $f_{n'}$, $f_n$]  \n",
    "Bias term = 1D tensor [$f_n$]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layers\n",
    "\n",
    "The goal of pooling layers is **subsample** the input image in order to reduce the computational load, the memory usage, and the number of parameters. A pooling neuron has no weights, all it does is **aggregate inputs** using an aggregator function such as max or mean. \n",
    "\n",
    "#### TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# using max\n",
    "max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
    "# using average\n",
    "avg_pool = keras.layers.AvgPool2D(pool_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, mean pooling is more popular than average pooling probable because it maintains only the strongest feature, eliminating potential noise. Also, it takes less to compute and offers stronger translation invariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Architectures\n",
    "\n",
    "Typical CNN architectures stack a few convolutional layers (each one generally followed by a ReLU layer), then a pooling layer, then another few convolutional layers (+ReLU), then another pooling layer, and so on. Images gets **smaller and deeper** as they progress through the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\giuse\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\giuse\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\giuse\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\giuse\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\giuse\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                        input_shape=[28, 28, 1]),\n",
    "    # max pooling layer (pooling size 2)\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    # doubling n of filers in after each polling layer\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    # flatten input into 1D array\n",
    "    keras.layers.Flatten(),\n",
    "    # fully connected network\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pretrained Models from Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load pretrained networks very easily in Keras: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      " 91971584/102853048 [=========================>....] - ETA: 14s"
     ]
    }
   ],
   "source": [
    "model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
