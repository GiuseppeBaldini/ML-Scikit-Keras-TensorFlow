{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Deep Computer Vision Using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) emerged from the study of the brain’s visual cortex, and they have been used in image recognition since the 1980s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers\n",
    "\n",
    "Neurons in the first convolutional layer are **not** connected to every pixel in the input image but only to pixels in their receptive fields. Successive layers only concentrate on a rectangle of neurons in the previous layers. \n",
    "\n",
    "**Note**: in CNNs each layer is in 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neuron located in row $i$, column $j$ of a given layer is connected to the outputs of the neurons in the previous layer located in rows $i$ to $i + f_h – 1$, columns $j$ to $j + f_w – 1$, where $f_h$ and $f_w$ are the height and width of the receptive field. In order to have same height and weight for layers, zeros are added around inputs (**Zero padding**).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN_Layers](images/13.CNN_Layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shift from one receptive field to the next is called the **stride**. The ouput layer can be smaller than the input layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters\n",
    "\n",
    "Or **convolutional kernels** can be represented as a small image the size of the receptive field. These weights will put particular emphasis to certain features of the data (hence the names _feature map_ for their otput), e.g. horizontal lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Multiple Feature Maps\n",
    "\n",
    "In short, a convolutional layer simultaneously applies multiple trainable filters to its inputs, making it capable of detecting multiple features anywhere in its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Implementation\n",
    "\n",
    "Input image = 3D tensor [_height, width, channels_]  \n",
    "Mini-batch = 4D tensor [_mini-batch size, height, width, channels_]  \n",
    "CNN weights = 4D tensor [$f_h$, $f_w$, $f_{n'}$, $f_n$]  \n",
    "Bias term = 1D tensor [$f_n$]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layers\n",
    "\n",
    "The goal of pooling layers is **subsample** the input image in order to reduce the computational load, the memory usage, and the number of parameters. A pooling neuron has no weights, all it does is **aggregate inputs** using an aggregator function such as max or mean. \n",
    "\n",
    "#### TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# using max\n",
    "max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
    "# using average\n",
    "avg_pool = keras.layers.AvgPool2D(pool_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, mean pooling is more popular than average pooling probable because it maintains only the strongest feature, eliminating potential noise. Also, it takes less to compute and offers stronger translation invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
