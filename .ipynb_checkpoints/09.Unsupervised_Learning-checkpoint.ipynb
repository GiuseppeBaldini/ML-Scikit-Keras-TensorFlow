{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although most applications today are in supervised learning, most of the data available is actually unlabeled. \n",
    "\n",
    "Here is where unsupervised learning shines. In this chapter, we will look at three unsupervised learning tasks:\n",
    "\n",
    "1. **Clustering**: group similar instances in classes\n",
    "2. **Anomaly detection**: learn what is normal data to detect abnormal instances\n",
    "3. **Density estimation**: estimating the probability density function (PDF) of the random process that generated the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clustering\n",
    "\n",
    "Examples of clustering algorithms include:* \n",
    "\n",
    "* Segmentation\n",
    "* Data analysis\n",
    "* Dimensionality reduction\n",
    "* Anomaly detection\n",
    "* Semi-supervised learning\n",
    "* Search engines\n",
    "* Image compression\n",
    "\n",
    "Let's now look at two particular algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means\n",
    "\n",
    "K-means is a relatively simple yet powerful algorithm that will try to find each cluster’s center and assign each instance to the closest cluster.\n",
    "\n",
    "Let's try it out on built-in blobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "\n",
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of clustering, an instance’s label is the index of the cluster that this instance gets assigned to by the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 2, ..., 3, 2, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred is kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have a look at the centroids:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use them to quickly assign new instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of assigning each instance to a single cluster (**hard clustering**), it can be useful to just give each instance a score per cluster (**soft clustering**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means algorithm\n",
    "\n",
    "The algorithm works by initially placing clusters in a random position and iterating until convergence, which usually happens in few steps and linear computational complexity with regards to the number of instances _m_, the number of clusters _k_ and the number of dimensions _n_.\n",
    "\n",
    "However, guarantee of convergence is not guarantee of global optimum. Improving centroid initialization can therefore lead to better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do this by:\n",
    "\n",
    "1. Setting the centroids ourselves, usually after running a first random init iteration\n",
    "2. Run the algorithm multiple times with different random initializations and keep the best solution (the one with minimal _inertia_ - mean squared distance between each instance and its closest centroid)\n",
    "3. Use the K-means +/+ implementation which works by selecting centroids that are distance from one another\n",
    "\n",
    "The last option, developed by David Arthur and Sergei Vassilvitskii in 2006, is the default Scikit-learn implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accelerated K-means and Mini-batch K-means \n",
    "\n",
    "Another improvement to the algorithm was proposed by Charles Elkan in 2003 and take advantage of the triangle inequality ($AC ≤ AB + BC$) to reduce computation of the distances. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
